# FILE: .env

# =============================================================================
# ROUTER DEBUG MODE
# =============================================================================
ORB_ROUTER_DEBUG=1

# =============================================================================
# API KEYS
# =============================================================================
OPENAI_API_KEY=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
ANTHROPIC_API_KEY=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
GOOGLE_API_KEY=AIzaSyCEuinZoc3r-QlyvW8PzTIU_EClb4GBv3M

# =============================================================================
# MODEL CONFIGURATION — GENERAL
# =============================================================================
# IMPORTANT:
# - Streaming chat-completions MUST use chat-capable model IDs.
# - gpt-5.2-pro requires Responses API (handled automatically by registry.py)
# - Use gpt-5.2-chat-latest for streaming chat paths.

# OpenAI defaults
OPENAI_DEFAULT_MODEL=gpt-5-mini
OPENAI_MODEL_LIGHT_CHAT=gpt-5-mini
OPENAI_MODEL_HEAVY_TEXT=gpt-5.2-chat-latest
OPENAI_MODEL_CRITICAL=gpt-5.2-chat-latest

# Anthropic
ANTHROPIC_SONNET_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_OPUS_MODEL=claude-opus-4-5-20251101

# Google Gemini
GEMINI_DEFAULT_MODEL=gemini-2.0-flash
GEMINI_VISION_MODEL_FAST=gemini-2.5-pro
GEMINI_VISION_MODEL_COMPLEX=gemini-2.5-pro
GEMINI_VIDEO_HEAVY_MODEL=gemini-3-pro-preview

# =============================================================================
# ASTRA PIPELINE — STAGE ASSIGNMENTS
# =============================================================================
# Cost-Accuracy Baseline v1.2
# Strategy:
# - Pro models for decision gates (Spec Gate + Overwatch): short, structured outputs.
# - Cheaper/frontier models for long-form generation (Opus/Sonnet/Gemini).
#
# Token policy:
# - DEFAULT caps are the normal safety rails (prevents runaway cost/verbosity).
# - BREAK-GLASS caps are only used when explicitly enabled per job/stage.
#   (Implementation must choose DEFAULT vs BREAK-GLASS based on a flag.)

# -----------------------------------------------------------------------------
# Spec Gate (creates PoT spec, defines requirements)
# -----------------------------------------------------------------------------
# Decision-only, no streaming. Highest accuracy needed.
# Output contract: QUESTIONS + PoT Spec summary (no code, no diffs).
OPENAI_SPEC_GATE_MODEL=gpt-5.2-pro

# Default vs break-glass output caps (Responses API)
SPEC_GATE_MAX_OUTPUT_TOKENS_DEFAULT=4000
SPEC_GATE_MAX_OUTPUT_TOKENS_BREAKGLASS=30000

# Flag (0/1) – if your runner supports per-job overrides, keep this 0 and override via job metadata instead.
SPEC_GATE_BREAKGLASS=0

# -----------------------------------------------------------------------------
# Architecture Draft (Opus generates initial architecture)
# -----------------------------------------------------------------------------
# Long-form document generation. Quality critical.
OPUS_DRAFT_MAX_TOKENS=60000
OPUS_TIMEOUT_SECONDS=300

# -----------------------------------------------------------------------------
# Revision Loop (Opus revises based on critique)
# -----------------------------------------------------------------------------
OPUS_REVISION_MAX_TOKENS=60000
OPUS_REVISION_TIMEOUT=300

# -----------------------------------------------------------------------------
# Critique (Gemini reviews architecture against spec)
# -----------------------------------------------------------------------------
# Frontier reasoning for QA. Keep long cap for detailed critique JSON.
GEMINI_CRITIC_MODEL=gemini-3-pro-preview
GEMINI_CRITIC_MAX_TOKENS=60000

# -----------------------------------------------------------------------------
# Streaming default
# -----------------------------------------------------------------------------
ANTHROPIC_STREAM_MAX_TOKENS=60000

# -----------------------------------------------------------------------------
# Planner (breaks work into chunks)
# -----------------------------------------------------------------------------
ASTRA_PLANNER_MODEL=gpt-5.2-chat-latest
ASTRA_PLANNER_MAX_TOKENS=60000

# -----------------------------------------------------------------------------
# Implementer (writes/refactors code)
# -----------------------------------------------------------------------------
ASTRA_IMPLEMENTER_MODEL=claude-sonnet-4-5-20250929
ASTRA_IMPLEMENTER_FALLBACK=gpt-5.2-chat-latest
ASTRA_IMPLEMENTER_MAX_TOKENS=60000

# -----------------------------------------------------------------------------
# Overwatch (final promotion gate)
# -----------------------------------------------------------------------------
# Decision-only, security/invariants check. Output must stay compact.
# Output contract: DECISION / DIAGNOSIS / FIX_ACTIONS / CONSTRAINTS / VERIFICATION
ASTRA_OVERWATCH_MODEL=gpt-5.2-pro
ASTRA_OVERWATCH_ROLE=promotion_gate_only

ASTRA_OVERWATCH_MAX_OUTPUT_DEFAULT=1200
ASTRA_OVERWATCH_MAX_OUTPUT_BREAKGLASS=12000
ASTRA_OVERWATCH_BREAKGLASS=0
# =============================================================================
# COST REFERENCE (Standard tier, per 1M tokens)
# =============================================================================
# Model                    | Input    | Output   | Max Output | Notes
# -------------------------|----------|----------|------------|------------------
# gpt-5-mini               | $0.25    | $2.00    | 128,000    | Cheap default
# gpt-5.2-chat-latest      | $1.75    | $14.00   | 128,000    | Quality chat
# gpt-5.2-pro              | $21.00   | $168.00  | 128,000    | Decision gates
# claude-sonnet-4.5        | $3.00    | $15.00   | 128,000    | Code generation
# claude-opus-4.5          | $5.00    | $25.00   | 128,000    | Architecture docs
# gemini-3-pro             | $2.00    | $12.00   | 65,536     | Critique/QA
# gemini-2.0-flash         | $0.10    | $0.40    | 65,536     | Fast/cheap fallback
# =============================================================================

# =============================================================================
# TRACKING & METRICS
# =============================================================================
# Enable detailed tracking for cost/accuracy analysis
ORB_TRACKING_ENABLED=1

# Log token usage per stage
ORB_LOG_TOKEN_USAGE=1

# Log model decisions and routing
ORB_LOG_ROUTING_DECISIONS=1

# Log critique pass/fail with reasons
ORB_LOG_CRITIQUE_DETAILS=1

# Log revision loop iterations
ORB_LOG_REVISION_ITERATIONS=1

# Metrics output location
ORB_METRICS_DIR=D:\Orb\metrics

# Per-job cost tracking
ORB_TRACK_JOB_COSTS=1

# =============================================================================
# ACCURACY BASELINE TARGETS
# =============================================================================
# Spec Gate:      99%+ specs complete/unambiguous
# Critique:       <3 iterations avg to pass
# Stage 3 verify: 95%+ pass hash verification
# Overwatch:      100% must pass (safety critical)
# =============================================================================

# =============================================================================
# AUDIT & DEBUG
# =============================================================================
ORB_AUDIT_ENABLED=1
ORB_DEBUG_LOGGING=1
ORB_MIN_CRITIQUE_CHARS=1500

# =============================================================================
# AUTHENTICATION
# =============================================================================
# ORB_AUTH_ENABLED=true
# ORB_AUTH_SECRET_KEY=your_secret_key_here

# =============================================================================
# DATABASE
# =============================================================================
# DATABASE_URL=sqlite:///./orb.db

# =============================================================================
# CORS
# =============================================================================
# CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# =============================================================================
# ZOBIE / ARCHMAP LOCAL TOOLS
# =============================================================================
ORB_ZOBIE_CONTROLLER_URL=http://192.168.250.2:8765
ORB_ZOBIE_MAPPER_SCRIPT=D:\tools\zobie_mapper\zobie_map.py
ORB_ZOBIE_MAPPER_OUT_DIR=D:\tools\zobie_mapper\out
ORB_ZOBIE_MAPPER_TIMEOUT_SEC=300
ORB_ZOBIE_MAPPER_ARGS=

# ARCHMAP LLM (latest GPT for mapping)
ORB_ZOBIE_ARCHMAP_PROVIDER=openai
ORB_ZOBIE_ARCHMAP_MODEL=gpt-5.2-chat-latest

# Optional style template
# ORB_ZOBIE_ARCHMAP_TEMPLATE_PATH=D:\tools\zobie_mapper\out\orb_architecture_map_v31.md
ORB_ZOBIE_ARCHMAP_TEMPLATE_MAX_CHARS=20000

# Multi-pass + file-first behavior
ORB_ZOBIE_ARCHMAP_MULTI_PASS=1
ORB_ZOBIE_ARCHMAP_WRITE_SECTIONS=1
ORB_ZOBIE_ARCHMAP_WRITE_FULL_FILE=1

# UI behavior: progress + short summary only
ORB_ZOBIE_ARCHMAP_STREAM_CONTENT=0
ORB_ZOBIE_ARCHMAP_SUMMARY_IN_SSE=1

# Hard bounds (prevents context_length_exceeded)
ORB_ZOBIE_ARCHMAP_MAX_FILES=200000
ORB_ZOBIE_ARCHMAP_SECTION_MAX_CODE_FILES=120
ORB_ZOBIE_ARCHMAP_SECTION_MAX_CHARS_PER_FILE=18000
ORB_ZOBIE_ARCHMAP_SECTION_MAX_SCANNED_FILES=120
ORB_ZOBIE_ARCHMAP_MAX_ARTIFACT_CHARS=200000
ORB_ZOBIE_ARCHMAP_MAX_COMPLETION_TOKENS=6000

# Memory ingest
ORB_ZOBIE_ARCHMAP_INGEST_TO_MEMORY=1
ORB_ZOBIE_ARCHMAP_INGEST_SECTIONS_TO_MEMORY=1
ORB_ZOBIE_ARCHMAP_DOC_RAW_MAX_CHARS=60000
