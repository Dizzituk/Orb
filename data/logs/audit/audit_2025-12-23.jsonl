{"ts": "2025-12-23T10:20:06.653+00:00", "event": "REQUEST_START", "request_id": "a46469ae-c88c-4776-b5a1-5f74c40851f9", "session_id": "legacy-c627866f-456f-4085-b1de-b79160483210", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-23T10:20:06.654+00:00", "event": "REQUEST_START", "request_id": "a46469ae-c88c-4776-b5a1-5f74c40851f9", "session_id": "legacy-c627866f-456f-4085-b1de-b79160483210", "project_id": 26, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:20:06.654+00:00", "event": "ROUTING_DECISION", "request_id": "a46469ae-c88c-4776-b5a1-5f74c40851f9", "session_id": "legacy-c627866f-456f-4085-b1de-b79160483210", "project_id": 26, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:20:27.913+00:00", "event": "MODEL_CALL", "request_id": "a46469ae-c88c-4776-b5a1-5f74c40851f9", "session_id": "legacy-c627866f-456f-4085-b1de-b79160483210", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21257, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-23T10:20:27.913+00:00", "event": "TRACE_END", "request_id": "a46469ae-c88c-4776-b5a1-5f74c40851f9", "session_id": "legacy-c627866f-456f-4085-b1de-b79160483210", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21260, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-23T10:24:08.216+00:00", "event": "REQUEST_START", "request_id": "1f13b073-1656-4f1f-b210-ca74c1ddda15", "session_id": "legacy-47884e8b-a619-4b46-8cc4-8be8d5891735", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-23T10:24:08.217+00:00", "event": "REQUEST_START", "request_id": "1f13b073-1656-4f1f-b210-ca74c1ddda15", "session_id": "legacy-47884e8b-a619-4b46-8cc4-8be8d5891735", "project_id": 26, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:24:08.217+00:00", "event": "ROUTING_DECISION", "request_id": "1f13b073-1656-4f1f-b210-ca74c1ddda15", "session_id": "legacy-47884e8b-a619-4b46-8cc4-8be8d5891735", "project_id": 26, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:24:17.009+00:00", "event": "MODEL_CALL", "request_id": "1f13b073-1656-4f1f-b210-ca74c1ddda15", "session_id": "legacy-47884e8b-a619-4b46-8cc4-8be8d5891735", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 8764, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "OpenAI HTTP 400: {\n  \"error\": {\n    \"message\": \"Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.\",\n    \"type\": \"invalid_request_error\",\n    \"param\": \"temperature\",\n    \"code\": \"unsupported_value\"\n  }\n}"}}
{"ts": "2025-12-23T10:24:17.010+00:00", "event": "TRACE_END", "request_id": "1f13b073-1656-4f1f-b210-ca74c1ddda15", "session_id": "legacy-47884e8b-a619-4b46-8cc4-8be8d5891735", "project_id": 26, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 8794, "error": {"type": "TRACE_END", "message": "OpenAI HTTP 400: {\n  \"error\": {\n    \"message\": \"Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.\",\n    \"type\": \"invalid_request_error\",\n    \"param\": \"temperature\",\n    \"code\": \"unsupported_value\"\n  }\n}"}}
{"ts": "2025-12-23T10:36:17.926+00:00", "event": "REQUEST_START", "request_id": "ac5cf3f0-24e4-4278-8e2c-681aea4b661b", "session_id": "legacy-ce526cd1-b55e-4096-a446-2efda35798cd", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-23T10:36:17.926+00:00", "event": "REQUEST_START", "request_id": "ac5cf3f0-24e4-4278-8e2c-681aea4b661b", "session_id": "legacy-ce526cd1-b55e-4096-a446-2efda35798cd", "project_id": 27, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:36:17.926+00:00", "event": "ROUTING_DECISION", "request_id": "ac5cf3f0-24e4-4278-8e2c-681aea4b661b", "session_id": "legacy-ce526cd1-b55e-4096-a446-2efda35798cd", "project_id": 27, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-23T10:38:41.511+00:00", "event": "MODEL_CALL", "request_id": "ac5cf3f0-24e4-4278-8e2c-681aea4b661b", "session_id": "legacy-ce526cd1-b55e-4096-a446-2efda35798cd", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 142249, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-23T10:38:41.511+00:00", "event": "TRACE_END", "request_id": "ac5cf3f0-24e4-4278-8e2c-681aea4b661b", "session_id": "legacy-ce526cd1-b55e-4096-a446-2efda35798cd", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "ok": true, "latency_ms": 143585}
{"ts": "2025-12-23T10:40:04.920+00:00", "event": "REQUEST_START", "request_id": "8184c7b1-7dac-42f5-8675-7cd58b8fe14f", "session_id": "legacy-8e330388-e90d-4058-a565-090719ddd7ae", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=80"}
{"ts": "2025-12-23T10:40:06.447+00:00", "event": "REQUEST_START", "request_id": "8184c7b1-7dac-42f5-8675-7cd58b8fe14f", "session_id": "legacy-8e330388-e90d-4058-a565-090719ddd7ae", "project_id": 27, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "casual_chat", "provider": "openai", "model": "gpt-5-mini", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Job-type routing: casual_chat -> openai/gpt-5-mini"}
{"ts": "2025-12-23T10:40:06.447+00:00", "event": "ROUTING_DECISION", "request_id": "8184c7b1-7dac-42f5-8675-7cd58b8fe14f", "session_id": "legacy-8e330388-e90d-4058-a565-090719ddd7ae", "project_id": 27, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "casual_chat", "provider": "openai", "model": "gpt-5-mini", "note": "Job-type routing: casual_chat -> openai/gpt-5-mini"}
{"ts": "2025-12-23T10:40:45.895+00:00", "event": "MODEL_CALL", "request_id": "8184c7b1-7dac-42f5-8675-7cd58b8fe14f", "session_id": "legacy-8e330388-e90d-4058-a565-090719ddd7ae", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5-mini", "ok": true, "latency_ms": 36342, "tokens": {"prompt": 2403, "completion": 2224, "total": 4627}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-23T10:40:45.895+00:00", "event": "TRACE_END", "request_id": "8184c7b1-7dac-42f5-8675-7cd58b8fe14f", "session_id": "legacy-8e330388-e90d-4058-a565-090719ddd7ae", "project_id": 27, "flags": {"critical": false, "sandbox": false}, "ok": true, "latency_ms": 40975}
{"ts": "2025-12-23T10:46:59.417+00:00", "event": "REQUEST_START", "request_id": "d71dbded-0ff9-4a10-9a1c-57d346981b60", "session_id": "legacy-a388b381-5960-43a8-87f7-6704b5f8633e", "project_id": 1, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=0"}
{"ts": "2025-12-23T10:46:59.418+00:00", "event": "REQUEST_START", "request_id": "d71dbded-0ff9-4a10-9a1c-57d346981b60", "session_id": "legacy-a388b381-5960-43a8-87f7-6704b5f8633e", "project_id": 1, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "unknown", "provider": "", "model": "", "attachments": {"count": 1, "total_bytes": 159094, "by_kind": {"text": 1}}, "note": "HARD OVERRIDE: CHAT_LIGHT forced to GPT mini"}
{"ts": "2025-12-23T10:46:59.418+00:00", "event": "ROUTING_DECISION", "request_id": "d71dbded-0ff9-4a10-9a1c-57d346981b60", "session_id": "legacy-a388b381-5960-43a8-87f7-6704b5f8633e", "project_id": 1, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "chat.light", "provider": "openai", "model": "gpt-5-nano", "note": "HARD OVERRIDE: CHAT_LIGHT forced to GPT mini"}
{"ts": "2025-12-23T10:47:00.069+00:00", "event": "MODEL_CALL", "request_id": "d71dbded-0ff9-4a10-9a1c-57d346981b60", "session_id": "legacy-a388b381-5960-43a8-87f7-6704b5f8633e", "project_id": 1, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5-nano", "ok": false, "latency_ms": 651, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Error code: 400 - {'error': {'message': \"Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}"}}
{"ts": "2025-12-23T10:47:00.070+00:00", "event": "TRACE_END", "request_id": "d71dbded-0ff9-4a10-9a1c-57d346981b60", "session_id": "legacy-a388b381-5960-43a8-87f7-6704b5f8633e", "project_id": 1, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 653, "error": {"type": "TRACE_END", "message": "Error code: 400 - {'error': {'message': \"Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}"}}
