{"ts": "2025-12-22T05:50:29.222+00:00", "event": "REQUEST_START", "request_id": "ea8966a9-0985-4ab5-b1c5-5082019fb57e", "session_id": "legacy-12f4461d-5366-4fd5-915e-9a293857bafd", "project_id": 19, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T05:50:29.222+00:00", "event": "REQUEST_START", "request_id": "ea8966a9-0985-4ab5-b1c5-5082019fb57e", "session_id": "legacy-12f4461d-5366-4fd5-915e-9a293857bafd", "project_id": 19, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T05:50:29.223+00:00", "event": "ROUTING_DECISION", "request_id": "ea8966a9-0985-4ab5-b1c5-5082019fb57e", "session_id": "legacy-12f4461d-5366-4fd5-915e-9a293857bafd", "project_id": 19, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T05:50:50.457+00:00", "event": "MODEL_CALL", "request_id": "ea8966a9-0985-4ab5-b1c5-5082019fb57e", "session_id": "legacy-12f4461d-5366-4fd5-915e-9a293857bafd", "project_id": 19, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21232, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T05:50:50.457+00:00", "event": "TRACE_END", "request_id": "ea8966a9-0985-4ab5-b1c5-5082019fb57e", "session_id": "legacy-12f4461d-5366-4fd5-915e-9a293857bafd", "project_id": 19, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21235, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T05:54:17.666+00:00", "event": "REQUEST_START", "request_id": "c6193aa2-8437-42ca-a05f-0b7c15e2a12d", "session_id": "legacy-c902667c-62e3-4a0c-9d98-5136417b81d5", "project_id": 20, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T05:54:17.666+00:00", "event": "REQUEST_START", "request_id": "c6193aa2-8437-42ca-a05f-0b7c15e2a12d", "session_id": "legacy-c902667c-62e3-4a0c-9d98-5136417b81d5", "project_id": 20, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T05:54:17.667+00:00", "event": "ROUTING_DECISION", "request_id": "c6193aa2-8437-42ca-a05f-0b7c15e2a12d", "session_id": "legacy-c902667c-62e3-4a0c-9d98-5136417b81d5", "project_id": 20, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T05:54:38.860+00:00", "event": "MODEL_CALL", "request_id": "c6193aa2-8437-42ca-a05f-0b7c15e2a12d", "session_id": "legacy-c902667c-62e3-4a0c-9d98-5136417b81d5", "project_id": 20, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21191, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T05:54:38.860+00:00", "event": "TRACE_END", "request_id": "c6193aa2-8437-42ca-a05f-0b7c15e2a12d", "session_id": "legacy-c902667c-62e3-4a0c-9d98-5136417b81d5", "project_id": 20, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21194, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T06:01:54.585+00:00", "event": "REQUEST_START", "request_id": "927b5379-3178-4294-9f27-14224cd83da6", "session_id": "legacy-0e1b3ff6-c9ad-4e5c-a4f3-4b81e22e8180", "project_id": 21, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T06:01:54.586+00:00", "event": "REQUEST_START", "request_id": "927b5379-3178-4294-9f27-14224cd83da6", "session_id": "legacy-0e1b3ff6-c9ad-4e5c-a4f3-4b81e22e8180", "project_id": 21, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:01:54.586+00:00", "event": "ROUTING_DECISION", "request_id": "927b5379-3178-4294-9f27-14224cd83da6", "session_id": "legacy-0e1b3ff6-c9ad-4e5c-a4f3-4b81e22e8180", "project_id": 21, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:02:15.808+00:00", "event": "MODEL_CALL", "request_id": "927b5379-3178-4294-9f27-14224cd83da6", "session_id": "legacy-0e1b3ff6-c9ad-4e5c-a4f3-4b81e22e8180", "project_id": 21, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21220, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T06:02:15.808+00:00", "event": "TRACE_END", "request_id": "927b5379-3178-4294-9f27-14224cd83da6", "session_id": "legacy-0e1b3ff6-c9ad-4e5c-a4f3-4b81e22e8180", "project_id": 21, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21223, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T06:17:15.833+00:00", "event": "REQUEST_START", "request_id": "02f36c9e-a228-4cd0-a5e6-21a64706bfc1", "session_id": "legacy-83024eea-6abf-4dad-a90a-5bdc6dc3e756", "project_id": 22, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T06:17:15.834+00:00", "event": "REQUEST_START", "request_id": "02f36c9e-a228-4cd0-a5e6-21a64706bfc1", "session_id": "legacy-83024eea-6abf-4dad-a90a-5bdc6dc3e756", "project_id": 22, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:17:15.834+00:00", "event": "ROUTING_DECISION", "request_id": "02f36c9e-a228-4cd0-a5e6-21a64706bfc1", "session_id": "legacy-83024eea-6abf-4dad-a90a-5bdc6dc3e756", "project_id": 22, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:17:29.088+00:00", "event": "MODEL_CALL", "request_id": "02f36c9e-a228-4cd0-a5e6-21a64706bfc1", "session_id": "legacy-83024eea-6abf-4dad-a90a-5bdc6dc3e756", "project_id": 22, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 13252, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"}}
{"ts": "2025-12-22T06:17:29.089+00:00", "event": "TRACE_END", "request_id": "02f36c9e-a228-4cd0-a5e6-21a64706bfc1", "session_id": "legacy-83024eea-6abf-4dad-a90a-5bdc6dc3e756", "project_id": 22, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 13256, "error": {"type": "TRACE_END", "message": "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"}}
{"ts": "2025-12-22T06:25:23.650+00:00", "event": "REQUEST_START", "request_id": "9c8d088d-d08e-4885-8c6d-fd05bcc3b38b", "session_id": "legacy-ab1ec846-7053-4c11-bfcd-4fbda2b11cf5", "project_id": 23, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T06:25:23.650+00:00", "event": "REQUEST_START", "request_id": "9c8d088d-d08e-4885-8c6d-fd05bcc3b38b", "session_id": "legacy-ab1ec846-7053-4c11-bfcd-4fbda2b11cf5", "project_id": 23, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:25:23.650+00:00", "event": "ROUTING_DECISION", "request_id": "9c8d088d-d08e-4885-8c6d-fd05bcc3b38b", "session_id": "legacy-ab1ec846-7053-4c11-bfcd-4fbda2b11cf5", "project_id": 23, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T06:26:28.322+00:00", "event": "MODEL_CALL", "request_id": "9c8d088d-d08e-4885-8c6d-fd05bcc3b38b", "session_id": "legacy-ab1ec846-7053-4c11-bfcd-4fbda2b11cf5", "project_id": 23, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 64670, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Error code: 400 - {'error': {'message': 'Input tokens exceed the configured limit of 272000 tokens. Your messages resulted in 272547 tokens. Please reduce the length of the messages.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"}}
{"ts": "2025-12-22T06:26:28.322+00:00", "event": "TRACE_END", "request_id": "9c8d088d-d08e-4885-8c6d-fd05bcc3b38b", "session_id": "legacy-ab1ec846-7053-4c11-bfcd-4fbda2b11cf5", "project_id": 23, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 64672, "error": {"type": "TRACE_END", "message": "Error code: 400 - {'error': {'message': 'Input tokens exceed the configured limit of 272000 tokens. Your messages resulted in 272547 tokens. Please reduce the length of the messages.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"}}
{"ts": "2025-12-22T10:16:32.724+00:00", "event": "REQUEST_START", "request_id": "23c4e0eb-76cf-4dad-bd41-c1eb75907a12", "session_id": "legacy-4b974c30-481f-45e9-b283-37218f49f48c", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T10:16:32.725+00:00", "event": "REQUEST_START", "request_id": "23c4e0eb-76cf-4dad-bd41-c1eb75907a12", "session_id": "legacy-4b974c30-481f-45e9-b283-37218f49f48c", "project_id": 24, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T10:16:32.725+00:00", "event": "ROUTING_DECISION", "request_id": "23c4e0eb-76cf-4dad-bd41-c1eb75907a12", "session_id": "legacy-4b974c30-481f-45e9-b283-37218f49f48c", "project_id": 24, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T10:16:53.976+00:00", "event": "MODEL_CALL", "request_id": "23c4e0eb-76cf-4dad-bd41-c1eb75907a12", "session_id": "legacy-4b974c30-481f-45e9-b283-37218f49f48c", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21249, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T10:16:53.976+00:00", "event": "TRACE_END", "request_id": "23c4e0eb-76cf-4dad-bd41-c1eb75907a12", "session_id": "legacy-4b974c30-481f-45e9-b283-37218f49f48c", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21252, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T10:19:34.072+00:00", "event": "REQUEST_START", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T10:19:34.072+00:00", "event": "REQUEST_START", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T10:19:34.072+00:00", "event": "ROUTING_DECISION", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T10:19:58.170+00:00", "event": "MODEL_CALL", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "section_1", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 0, "tokens": {"prompt": 18853, "completion": 1335, "total": 20188}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-22T10:20:18.003+00:00", "event": "MODEL_CALL", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "section_2", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 0, "tokens": {"prompt": 15433, "completion": 2877, "total": 18310}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-22T10:20:37.051+00:00", "event": "MODEL_CALL", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "section_3", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 0, "tokens": {"prompt": 21081, "completion": 1547, "total": 22628}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-22T10:20:50.864+00:00", "event": "MODEL_CALL", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "section_4", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 0, "tokens": {"prompt": 16134, "completion": 1046, "total": 17180}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-22T10:21:14.845+00:00", "event": "MODEL_CALL", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "lane": "section_5", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": true, "latency_ms": 0, "tokens": {"prompt": 9509, "completion": 3089, "total": 12598}, "cost_usd": 0.0, "note": "role=primary"}
{"ts": "2025-12-22T10:21:17.885+00:00", "event": "TRACE_END", "request_id": "00e0b695-aa4a-4335-9f71-946f9e29341e", "session_id": "legacy-7de301db-ef23-434b-a1df-db0b5be6e726", "project_id": 24, "flags": {"critical": false, "sandbox": false}, "ok": true, "latency_ms": 103813}
{"ts": "2025-12-22T22:35:25.687+00:00", "event": "REQUEST_START", "request_id": "f120d69b-f5c0-4a31-b4f7-58dc443b2a65", "session_id": "legacy-2f9cc8fd-09c6-400e-9433-35efdad39d94", "project_id": 25, "flags": {"critical": false, "sandbox": false}, "job_type": "", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "user_text_len=23"}
{"ts": "2025-12-22T22:35:25.687+00:00", "event": "REQUEST_START", "request_id": "f120d69b-f5c0-4a31-b4f7-58dc443b2a65", "session_id": "legacy-2f9cc8fd-09c6-400e-9433-35efdad39d94", "project_id": 25, "flags": {"critical": false, "sandbox": false, "frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "attachments": {"count": 0, "total_bytes": 0, "by_kind": {}}, "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T22:35:25.688+00:00", "event": "ROUTING_DECISION", "request_id": "f120d69b-f5c0-4a31-b4f7-58dc443b2a65", "session_id": "legacy-2f9cc8fd-09c6-400e-9433-35efdad39d94", "project_id": 25, "flags": {"frontier_override": false, "file_map_injected": false}, "job_type": "local.architecture_map", "provider": "openai", "model": "gpt-5.2-chat-latest", "note": "Local tool trigger: CREATE ARCHITECTURE MAP"}
{"ts": "2025-12-22T22:35:46.925+00:00", "event": "MODEL_CALL", "request_id": "f120d69b-f5c0-4a31-b4f7-58dc443b2a65", "session_id": "legacy-2f9cc8fd-09c6-400e-9433-35efdad39d94", "project_id": 25, "flags": {"critical": false, "sandbox": false}, "lane": "primary", "provider": "openai", "model": "gpt-5.2-chat-latest", "ok": false, "latency_ms": 21235, "tokens": {"prompt": 0, "completion": 0, "total": 0}, "cost_usd": 0.0, "note": "role=primary", "error": {"type": "MODEL_CALL", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
{"ts": "2025-12-22T22:35:46.926+00:00", "event": "TRACE_END", "request_id": "f120d69b-f5c0-4a31-b4f7-58dc443b2a65", "session_id": "legacy-2f9cc8fd-09c6-400e-9433-35efdad39d94", "project_id": 25, "flags": {"critical": false, "sandbox": false}, "ok": false, "latency_ms": 21239, "error": {"type": "TRACE_END", "message": "Mapper failed (rc=1): Traceback (most recent call last):\r\n  File \u001b[35m\"G:\\Lib\\urllib\\request.py\"\u001b[0m, line \u001b[35m1319\u001b[0m, in \u001b[35mdo_open\u001b[0m\r\n    \u001b[31mh.request\u001b[0m\u001b[1;31m(req.get_method(), req.selector, req.data, headers,\u001b[0m\r\n    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^…"}}
