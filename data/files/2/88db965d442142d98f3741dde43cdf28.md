# Orb Architecture Map

**Version:** 0.10.1 (Architecture Map v8)  
**Last Updated:** 30 November 2025  
**Purpose:** Canonical architecture reference for the Orb multi-LLM AI assistant system

---

## Table of Contents

1. [System Overview](#system-overview)  
2. [Component Architecture](#component-architecture)  
3. [Backend (`Orb`)](#backend-orb)  
4. [Desktop Client (`orb-desktop`)](#desktop-client-orb-desktop)  
5. [Data Layer](#data-layer)  
6. [Authentication System](#authentication-system)  
7. [Database Encryption](#database-encryption)  
8. [Multi-LLM Orchestration](#multi-llm-orchestration)  
9. [DateTime Context](#datetime-context)  
10. [Streaming Responses](#streaming-responses)  
11. [Web Search](#web-search)  
12. [File Ingestion Pipeline](#file-ingestion-pipeline)  
13. [Image Analysis Pipeline](#image-analysis-pipeline)  
14. [Future Capabilities](#future-capabilities)  
15. [Changelog](#changelog)

---

## System Overview

Orb is a personal AI assistant built as a multi-component system with specialized LLM roles:

- **GPT (OpenAI)** â€” Fast/lightweight reasoning, conversational interface, linguistics  
- **Claude (Anthropic)** â€” Flagship engineer, complex code, architecture design  
- **Gemini (Google)** â€” Critic, reviewer, analyst, vision specialist, web search  

### Core Vision

Different AI models specialize in distinct roles while sharing a unified memory layer, enabling:

- Persistent knowledge management across conversations  
- Task coordination and project organization  
- Job-type-based automatic model routing  
- File upload with text extraction and document analysis  
- CV parsing with structured data extraction  
- Image analysis via Gemini Vision  
- RAG-based document retrieval for Q&A  
- **Password-based authentication with session tokens**
- **Project selector for multi-project management**
- **Database encryption at rest**
- **Streaming LLM responses**
- **Web search with real-time grounding**
- **Automatic datetime context in all LLM calls**

### Technology Stack

**Backend:**

- FastAPI (Python 3.13)  
- SQLAlchemy ORM  
- SQLite database  
- Pydantic schemas  
- bcrypt for password hashing  
- cryptography (Fernet) for field-level encryption  
- `python-multipart` for `multipart/form-data` file uploads  
- `python-docx` for DOCX text extraction  
- `PyMuPDF` (fitz) for PDF text extraction  
- `google-genai` for Gemini Web Search (new SDK, preferred)  
- `google-generativeai` for Gemini Vision + fallback (old SDK)  

**Desktop Client:**

- Electron (v33.0.0)  
- React 18 with TypeScript 5  
- Vite 5 (build tool and dev server)  
- Custom React hooks for state management  

**Platform:** Windows 11

---

## Component Architecture

```text
D:/
â”œâ”€â”€ Orb/                        # Backend (FastAPI server)
â”‚   â”œâ”€â”€ main.py                 # Application entrypoint, chat endpoints
â”‚   â”œâ”€â”€ .env                    # API keys (OPENAI, ANTHROPIC, GOOGLE)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ db.py               # Database configuration
â”‚   â”‚   â”œâ”€â”€ auth/               # Authentication module (password-based)
â”‚   â”‚   â”œâ”€â”€ crypto/             # Encryption module
â”‚   â”‚   â”œâ”€â”€ memory/             # Memory subsystem (projects/notes/tasks/files/messages)
â”‚   â”‚   â””â”€â”€ llm/                # LLM routing + vision + streaming + web search
â”‚   â”œâ”€â”€ data/                   # SQLite DB + file storage + auth config
â”‚   â”‚   â”œâ”€â”€ orb_memory.db       # SQLite database (encrypted fields)
â”‚   â”‚   â”œâ”€â”€ auth.json           # Password hash + session storage
â”‚   â”‚   â”œâ”€â”€ encryption_salt.bin # Salt for encryption key derivation
â”‚   â”‚   â””â”€â”€ files/              # Per-project file storage
â”‚   â”‚       â””â”€â”€ {project_id}/   # Uploaded project files
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ encrypt_existing_data.py  # Migration script for encryption
â”‚
â”œâ”€â”€ orb-desktop/                # Electron + React desktop client
â”‚   â”œâ”€â”€ main.js                 # Electron main process
â”‚   â”œâ”€â”€ index.html              # React mount point + CSP config
â”‚   â”œâ”€â”€ package.json            # Dependencies + scripts
â”‚   â”œâ”€â”€ vite.config.ts          # Vite configuration
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx            # React entry point
â”‚       â”œâ”€â”€ App.tsx             # Root component with auth + chat modes
â”‚       â”œâ”€â”€ components/         # React components
â”‚       â”‚   â”œâ”€â”€ AuthScreen.tsx  # Password setup/login UI
â”‚       â”‚   â”œâ”€â”€ ProjectSelector.tsx # Project dropdown
â”‚       â”‚   â”œâ”€â”€ Header.tsx      # App header with mode toggle
â”‚       â”‚   â”œâ”€â”€ ChatWindow.tsx  # Chat messages with streaming
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ hooks/              # Custom React hooks
â”‚       â”‚   â”œâ”€â”€ useAuth.ts      # Password authentication
â”‚       â”‚   â”œâ”€â”€ useProjects.ts  # Project management
â”‚       â”‚   â”œâ”€â”€ useChat.ts      # Chat state + streaming + web search
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ services/           # API client layer
â”‚       â””â”€â”€ styles/             # CSS styles
â”‚
â””â”€â”€ orb-electron-data/          # Electron userData directory
```

---

## Backend (`Orb`)

**Location:** `D:/Orb/`  
**Framework:** FastAPI  
**Entry Point:** `main.py`  
**Version:** 0.10.1

### Directory Structure

```text
Orb/
â”œâ”€â”€ main.py                 # FastAPI app, endpoints, context building, RAG
â”œâ”€â”€ .env                    # API keys and configuration
â”œâ”€â”€ start_orb_backend.bat   # Windows startup script
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db.py               # Database engine, session factory, Base
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/               # Authentication module
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Exports: require_auth, login, setup_password, etc.
â”‚   â”‚   â”œâ”€â”€ config.py       # Password hashing, session tokens, encryption init
â”‚   â”‚   â”œâ”€â”€ middleware.py   # FastAPI auth dependency
â”‚   â”‚   â””â”€â”€ router.py       # Auth endpoints (/auth/*)
â”‚   â”‚
â”‚   â”œâ”€â”€ crypto/             # Encryption module
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Exports: encrypt_string, decrypt_string, etc.
â”‚   â”‚   â”œâ”€â”€ encryption.py   # Fernet encryption with PBKDF2 key derivation
â”‚   â”‚   â””â”€â”€ types.py        # SQLAlchemy EncryptedText, EncryptedJSON types
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/             # Memory subsystem
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py       # SQLAlchemy ORM models (with encrypted columns)
â”‚   â”‚   â”œâ”€â”€ schemas.py      # Pydantic request/response schemas
â”‚   â”‚   â”œâ”€â”€ service.py      # Business logic (CRUD operations)
â”‚   â”‚   â””â”€â”€ router.py       # FastAPI route handlers (protected)
â”‚   â”‚
â”‚   â””â”€â”€ llm/                # LLM routing module
â”‚       â”œâ”€â”€ __init__.py     # Exports: call_llm, analyze_image, etc.
â”‚       â”œâ”€â”€ schemas.py      # JobType enum, LLMTask/LLMResult models
â”‚       â”œâ”€â”€ clients.py      # Provider API wrappers + datetime context
â”‚       â”œâ”€â”€ router.py       # Main router with call_llm()
â”‚       â”œâ”€â”€ gemini_vision.py # Gemini Vision for image analysis
â”‚       â”œâ”€â”€ file_analyzer.py # Text extraction and document analysis
â”‚       â”œâ”€â”€ streaming.py    # Streaming LLM responses + datetime context
â”‚       â”œâ”€â”€ stream_router.py # SSE streaming endpoint
â”‚       â”œâ”€â”€ web_search.py   # Gemini web grounding + datetime context
â”‚       â””â”€â”€ web_search_router.py # Web search endpoint
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ orb_memory.db       # SQLite database (encrypted fields)
â”‚   â”œâ”€â”€ auth.json           # Password hash + session config
â”‚   â”œâ”€â”€ encryption_salt.bin # Salt for key derivation
â”‚   â”œâ”€â”€ orb_memory_backup_pre_encryption.db  # Pre-encryption backup
â”‚   â””â”€â”€ files/              # Uploaded project files
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ encrypt_existing_data.py  # Encrypt existing DB data
â”‚
â””â”€â”€ static/                 # Web-based test interface
```

### Environment Configuration (`.env`)

```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...
GEMINI_VISION_MODEL=gemini-2.0-flash
```

### Core Endpoints

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `/` | GET | No | Static UI |
| `/ping` | GET | No | Health check |
| `/auth/status` | GET | No | Check auth type and status |
| `/auth/setup` | POST | No | Set up password (first time) |
| `/auth/login` | POST | No | Login with password |
| `/auth/logout` | POST | Yes | Logout (invalidate session) |
| `/auth/check` | GET | Yes | Verify session validity |
| `/auth/change-password` | POST | Yes | Change password |
| `/chat` | POST | Yes | Main chat with RAG |
| `/chat_with_attachments` | POST | Yes | File upload with analysis |
| `/stream/chat` | POST | Yes | **Streaming chat (SSE)** |
| `/stream/providers` | GET | Yes | Available streaming providers |
| `/search/status` | GET | Yes | **Web search availability** |
| `/search/query` | POST | Yes | **Web search with grounding** |
| `/llm` | POST | Yes | Direct LLM call |
| `/providers` | GET | Yes | Available providers |
| `/memory/*` | * | Yes | All memory CRUD |

---

## Authentication System

### Overview

Orb uses **password-based authentication** with session tokens. Passwords are hashed with bcrypt and stored locally. Session tokens are generated on login and stored in localStorage.

### Token Formats

- **Session tokens:** `orb_session_<64 hex chars>` (current)
- **Legacy API keys:** `orb_<32 hex chars>` (migration support)

### Auth Flow

1. Backend checks `data/auth.json` for `password_hash`
2. Frontend checks `/auth/status` â†’ returns `{configured, auth_type}`
3. If not configured â†’ setup screen (create password)
4. If configured â†’ login screen (enter password)
5. POST `/auth/login` â†’ returns `session_token`
6. Token stored in localStorage (key: `orb_session_token`)
7. All requests include `Authorization: Bearer <session_token>`
8. Logout invalidates session and clears encryption key

---

## Database Encryption

### Overview

Orb uses **field-level encryption** for sensitive data at rest. Encryption keys are derived from the user's password using PBKDF2.

### Crypto Module (`app/crypto/`)

```python
# encryption.py
def set_encryption_key(password: str) -> None:
    """Initialize encryption with password-derived key."""

def encrypt_string(plaintext: str) -> str:
    """Encrypt string. Returns 'ENC:...' prefixed ciphertext."""

def decrypt_string(ciphertext: str) -> str:
    """Decrypt string. Returns original plaintext."""

# types.py
class EncryptedText(TypeDecorator):
    """SQLAlchemy column type that auto-encrypts/decrypts."""

class EncryptedJSON(TypeDecorator):
    """Encrypted JSON column type."""
```

### Encrypted Columns

| Table | Column | Content |
|-------|--------|---------|
| `messages` | `content` | Chat history |
| `notes` | `content` | Personal notes |
| `tasks` | `description` | Task details |
| `files` | `description` | File descriptions |
| `document_contents` | `raw_text` | Extracted document text |
| `document_contents` | `summary` | Document summaries |
| `document_contents` | `structured_data` | CV data, parsed content |

### Key Derivation

```text
password â†’ PBKDF2 (480,000 iterations, SHA256) â†’ 32-byte key â†’ Fernet
```

Salt stored in `data/encryption_salt.bin` (generated once).

### Encryption Flow

1. **Login** â†’ Password verified â†’ Encryption key derived
2. **Write data** â†’ SQLAlchemy intercepts â†’ Encrypts â†’ Stores `ENC:...`
3. **Read data** â†’ SQLAlchemy intercepts â†’ Decrypts â†’ Returns plaintext
4. **Logout** â†’ Encryption key cleared from memory

### Migration Script

```powershell
cd D:\Orb
py -3.13 scripts/encrypt_existing_data.py
```

---

## DateTime Context

### Overview

All LLM calls include the **current date and time** in the system prompt. This ensures models have temporal awareness for time-sensitive queries.

### Implementation

```python
# clients.py, streaming.py, web_search.py

def get_datetime_context() -> str:
    """Get current date/time for system prompts."""
    now = datetime.now()
    formatted = now.strftime("%A, %B %d, %Y at %I:%M %p")
    # Add timezone if available
    return f"Current date and time: {formatted}"

def enhance_system_prompt(prompt: str) -> str:
    """Add datetime context to system prompt."""
    context = get_datetime_context()
    if prompt:
        return f"{context}\n\n{prompt}"
    return context
```

### Example Output

```text
Current date and time: Saturday, November 30, 2025 at 6:45 PM (GMT)

You are a helpful assistant...
```

### Coverage

DateTime context is automatically added to:

- **`clients.py`** â€” Regular chat (`call_openai`, `call_anthropic`, `call_gemini`)
- **`streaming.py`** â€” Streaming responses (`stream_openai`, `stream_anthropic`, `stream_gemini`)
- **`web_search.py`** â€” Web search queries (ensures current date in search context)

---

## Streaming Responses

### Overview

Orb supports **token-by-token streaming** using Server-Sent Events (SSE). Responses appear as they're generated, with a blinking cursor.

### Backend (`app/llm/streaming.py`)

```python
async def stream_llm(
    messages: List[Dict],
    system_prompt: str = "",  # DateTime added automatically
    provider: Optional[str] = None,
    model: Optional[str] = None,
) -> AsyncGenerator[str, None]:
    """Stream LLM response. Yields tokens as they arrive."""
```

Supports: OpenAI, Anthropic, Gemini

### SSE Format

```text
data: {"type": "metadata", "provider": "openai", "model": "gpt-4o-mini"}

data: {"type": "token", "content": "Hello"}

data: {"type": "token", "content": " world"}

data: {"type": "done", "provider": "openai", "total_length": 11}
```

### Frontend Integration

```typescript
// useChat.ts
const {
  isStreaming,        // true while streaming
  streamingContent,   // accumulated content
  sendMessageStreaming,
  cancelStream,
} = useChat(projectId);
```

### Chat Modes (App.tsx)

Click the mode button to cycle through:

- **ğŸ’¬ Chat** â€” Normal responses (wait for complete)
- **âš¡ Stream** â€” Streaming responses (default)
- **ğŸ” Search** â€” Web search with sources

---

## Web Search

### Overview

Orb can perform **real-time web search** using Gemini's grounding feature. Results include sources.

### SDK Strategy

Orb uses a **dual-SDK approach** for web search:

1. **Primary: `google-genai`** (new SDK)
   - Uses `Tool(google_search=GoogleSearch())` format
   - Full grounding support with sources
   - Required for Gemini 2.0+

2. **Fallback: `google-generativeai`** (old SDK)
   - Basic Gemini without grounding
   - No real-time search, uses model knowledge
   - Logs: `[web_search] Using old SDK (no grounding)`

### Installation

```powershell
# For full web search grounding:
py -3.13 -m pip install google-genai

# Fallback (already installed):
py -3.13 -m pip install google-generativeai
```

### Backend (`app/llm/web_search.py`)

```python
def search_and_answer(
    query: str,
    context: Optional[str] = None,
    history: Optional[List[Dict]] = None,
) -> Dict[str, Any]:
    """
    Perform web-grounded search query.
    Tries new SDK first, falls back to old SDK.
    DateTime context added automatically.
    Returns: {answer, sources, search_queries, provider}
    """
```

### API Endpoint

**POST `/search/query`**

```json
{
  "project_id": 1,
  "query": "What is the weather in London?",
  "include_history": true
}
```

**Response:**

```json
{
  "answer": "The current weather in London is...",
  "sources": [{"title": "...", "uri": "https://..."}],
  "search_queries": ["London weather today"],
  "provider": "gemini-grounded"
}
```

### Grounding Metadata

When using the new SDK, responses include:

- `webSearchQueries` â€” Queries the model used
- `groundingChunks` â€” Source URLs and titles
- `searchEntryPoint` â€” Rendered search widget HTML

### Startup Messages

```text
[web_search] google-genai SDK available (grounding enabled)
```
or
```text
[web_search] Using old google-generativeai SDK
```

---

## Multi-LLM Orchestration

### LLM Routing Module (`app/llm/`)

#### Job Types and Routing

- **GPT-only:** `casual_chat`, `note_cleanup`, `copywriting`, `summary`
- **Medium dev:** `simple_code_change`, `small_bugfix`
- **Claude (engineering):** `complex_code_change`, `codegen_full_file`, `architecture_design`
- **High-stakes:** `high_stakes_infra`, `security_sensitive_change`
- **Gemini:** `image_analysis`, `screenshot_analysis`, `web_search`

#### Models

- OpenAI: `gpt-4o-mini`
- Anthropic: `claude-sonnet-4-20250514`
- Google: `gemini-2.0-flash`

---

## File Ingestion Pipeline

### Flow: File Upload â†’ Extraction â†’ Storage â†’ RAG

```text
User uploads file(s)
       â”‚
       â–¼
POST /chat_with_attachments (requires session token)
       â”‚
       â”œâ”€â”€ Save to data/files/{project_id}/{uuid}.ext
       â”‚
       â”œâ”€â”€ Detect MIME type
       â”‚   â”œâ”€â”€ image/* â†’ Gemini Vision analysis
       â”‚   â””â”€â”€ other   â†’ Text extraction
       â”‚
       â”œâ”€â”€ extract_text_content()
       â”‚   â”œâ”€â”€ .docx â†’ python-docx
       â”‚   â”œâ”€â”€ .pdf  â†’ PyMuPDF
       â”‚   â””â”€â”€ .txt/.md â†’ plain read
       â”‚
       â”œâ”€â”€ detect_document_type() â†’ cv | code | config | document
       â”‚
       â”œâ”€â”€ If CV: parse_cv_with_llm() â†’ structured JSON
       â”‚
       â”œâ”€â”€ generate_document_summary()
       â”‚
       â”œâ”€â”€ Create File + DocumentContent records (encrypted)
       â”‚
       â””â”€â”€ Return ChatResponse with attachments_summary
```

---

## Image Analysis Pipeline

### Flow: Image Upload â†’ Gemini Vision â†’ Storage

```text
User uploads image
       â”‚
       â–¼
POST /chat_with_attachments
       â”‚
       â”œâ”€â”€ Save to data/files/{project_id}/{uuid}.png
       â”‚
       â”œâ”€â”€ Detect image/* MIME type
       â”‚
       â”œâ”€â”€ analyze_image(file_bytes, mime_type, user_prompt)
       â”‚         â”‚
       â”‚         â”œâ”€â”€ Initialize Gemini model
       â”‚         â”œâ”€â”€ Send image + prompt to Gemini Vision
       â”‚         â””â”€â”€ Parse JSON response: {summary, tags, type}
       â”‚
       â”œâ”€â”€ Create File + DocumentContent records (encrypted)
       â”‚
       â””â”€â”€ Return ChatResponse with image summary
```

---

## Future Capabilities

### Security Roadmap

- âœ… **Phase 1: Password Authentication** â€” Completed
- âœ… **Phase 2: Database Encryption** â€” Completed (field-level)
- **Phase 3: Secure Key Storage** â€” Electron secure storage / Windows Credential Manager
- **Phase 4: Audit Logging** â€” Track all API access with timestamps

### Feature Roadmap

- âœ… **Streaming Responses** â€” Completed
- âœ… **Web Search Grounding** â€” Completed (with google-genai SDK)
- âœ… **DateTime Context** â€” Completed (all LLM calls)
- **Semantic Search Over Notes & Files** â€” Embedding-based retrieval
- **Markdown Rendering** â€” Render code blocks, bold, lists
- **Chat History Load** â€” Load previous messages on project switch
- **Settings Panel** â€” Configure providers, models, API keys in UI
- **Theme Toggle** â€” Light/dark mode switch

---

## Changelog

### v0.10.1 â€” DateTime Context + Web Search SDK Fix (30 Nov 2025)

**Backend:**

- **DateTime Context:**
  - All LLM calls now include current date/time in system prompt
  - `get_datetime_context()` and `enhance_system_prompt()` helpers
  - Applied to: `clients.py`, `streaming.py`, `web_search.py`
  - Format: "Current date and time: Saturday, November 30, 2025 at 6:45 PM (GMT)"

- **Web Search SDK Migration:**
  - New SDK: `google-genai` (preferred, full grounding support)
  - Old SDK: `google-generativeai` (fallback, no grounding)
  - Tool format: `Tool(google_search=GoogleSearch())` instead of deprecated `google_search_retrieval`
  - Automatic fallback if new SDK not installed

- **clients.py Fixes:**
  - Fixed usage dict format (removed model string from usage)
  - Added `call_google` alias for backwards compatibility

**Dependencies:**

- Added: `google-genai` (optional, for full web search grounding)

### v0.10.0 â€” Database Encryption + Streaming + Web Search (30 Nov 2025)

**Backend:**

- **Database Encryption:**
  - New `app/crypto/` module with Fernet encryption
  - PBKDF2 key derivation from password (480,000 iterations)
  - `EncryptedText` and `EncryptedJSON` SQLAlchemy column types
  - Encrypted: messages, notes, tasks, document content
  - Migration script: `scripts/encrypt_existing_data.py`
  - Salt stored in `data/encryption_salt.bin`
  - Encryption key initialized on login, cleared on logout

- **Streaming Responses:**
  - New `app/llm/streaming.py` module
  - Server-Sent Events (SSE) endpoint: `/stream/chat`
  - Multi-provider support: OpenAI, Anthropic, Gemini
  - Metadata, token, done, and error event types

- **Web Search:**
  - New `app/llm/web_search.py` module
  - Gemini grounding with Google Search
  - Endpoint: `/search/query`
  - Source extraction and citation

**Frontend:**

- **Chat Modes:**
  - Mode toggle button in header (ğŸ’¬ Chat / âš¡ Stream / ğŸ” Search)
  - Streaming content display with blinking cursor
  - Cancel stream button during generation
  - Web search with `ğŸ”` prefix on queries

- **useChat Hook Updates:**
  - `sendMessageStreaming()` for streaming responses
  - `sendWebSearch()` for grounded search
  - `isStreaming` and `streamingContent` state
  - `cancelStream()` to abort generation

- **ChatWindow Updates:**
  - Streaming message display
  - Auto-scroll during streaming
  - Input disabled while streaming

**Dependencies:**

- Added: `cryptography` (Fernet encryption)
- Updated: `google-generativeai` (for grounding)

### v0.9.0 â€” Password Authentication + Project Selector (30 Nov 2025)

- Password-based authentication with bcrypt
- Session token system
- Project selector component
- UI fixes (scroll, drag-drop)

### v0.8.0 â€” API Authentication (30 Nov 2025)

- Initial API key authentication system

### v0.7.0 â€” React Migration + File Ingestion (29-30 Nov 2025)

- React 18 + TypeScript 5 migration
- File upload with text extraction
- CV parsing and Gemini Vision

---

## Quick Start

### Backend

```powershell
cd D:\Orb
py -3.13 -m uvicorn main:app --reload
```

### Desktop Client

```powershell
cd D:\orb-desktop
npm run electron:dev
```

### First-Time Setup

1. Start backend and frontend
2. App shows "Welcome to Orb" screen
3. Create a password (min 4 characters)
4. Enter the main app
5. Create your first project

### Install Web Search Grounding

```powershell
py -3.13 -m pip install google-genai
# Restart backend to enable full grounding
```

### Encrypt Existing Data

```powershell
cd D:\Orb
py -3.13 scripts/encrypt_existing_data.py
# Enter password when prompted
# Type "yes" to confirm
```

---

## Troubleshooting

### Encryption Issues

**"Decryption failed":**
- Wrong password entered
- Password was changed without re-encrypting data
- Run encryption script again with correct password

**"crypto module not available":**
```powershell
py -3.13 -m pip install cryptography
```

**Data shows as "ENC:..." in responses:**
- Encryption key not initialized
- Try logging out and back in

### Streaming Issues

**Stream doesn't start:**
- Check backend logs for errors
- Verify provider API keys are set
- Try a different provider

**Stream disconnects:**
- Network timeout
- Check backend is still running

### Web Search Issues

**"Using old SDK (no grounding)":**
```powershell
py -3.13 -m pip install google-genai
# Restart backend
```

**"google_search_retrieval is not supported":**
- Old SDK issue, install `google-genai`

**No sources in response:**
- Not all queries trigger grounding
- Try more specific, factual queries

**Wrong date/time in responses:**
- Verify backend was restarted after update
- Check `clients.py` has `enhance_system_prompt()` calls

### Backend Won't Start

**"No module named X":**
```powershell
py -3.13 -m pip install uvicorn fastapi bcrypt sqlalchemy python-multipart aiofiles cryptography google-generativeai google-genai
```

**Import errors after update:**
- Check for function name mismatches
- Verify `call_google` alias exists in `clients.py`

### Authentication Issues

**Forgot Password:**
```powershell
del D:\Orb\data\auth.json
del D:\Orb\data\encryption_salt.bin
# Restart backend, then set up new password
# Note: Encrypted data will be unreadable with new password
```
