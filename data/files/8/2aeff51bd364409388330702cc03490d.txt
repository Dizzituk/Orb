After-each-phase checklist (quick, repeatable; covers core invariants + what changed)

1 Routing & model labels
Non-stream call /chat:
 Send a casual prompt → expect OpenAI in response metadata/UI badge.
 Send a simple code prompt → expect Anthropic Sonnet.
 Send a complex/architecture prompt → expect Anthropic Opus.
 Send an image/screenshot → expect Gemini (Flash tier).
Stream call /stream/chat:
 Verify first SSE metadata event includes provider+model; tokens stream; done event closes cleanly.
DB/UI: message rows save provider + model; badges render.

2 Memory (per-project, no bleed)
New TestProject-P: send 3 messages + 1 note.
Switch to another project and back; restart backend and desktop; confirm history + notes persist; confirm no cross-contamination.

3 Security (Level-4)
is_encryption_ready (or equivalent) returns true; master key present in Windows Credential Manager; no plaintext secrets in logs or DB; .env not leaked in console.

4 UI basics
Chat scroll: can scroll up, new tokens don’t yank position; autoscroll on latest.
Markdown renders (lists, code blocks with highlighting); reasoning/answer panels look right; model badge visible.

5 Uploads & vision
Drag-drop small file → progress + clear success.
Upload image → routed to Gemini; response sensible; model badge correct.

6 Web search / tools (if enabled)
Simple web search via endpoint returns grounded snippets; errors handled without crashing router.

7 Embeddings / semantic search (if touched)
Add a note/file; re-index auto-runs; search can retrieve it by meaning.

8 Delta checks (only for modules you touched this phase)
For each changed module, run Happy path / Failure path / Restart-persistence / Log sanity:
Memory: CRUD paths; cross-project isolation; restart.
Router: classification logs show expected JobType → provider/model mapping; ambiguous inputs choose safe default.
Vision: outbound payload format; provider receives the right modality; large image → graceful handling.
Streaming: back-pressure, early cancel, provider switch still emits done/closes stream.
Provider registry: rate-limit + retry paths don’t wedge the app.

9 Bug capture & handoff
Record P0/P1/P2, steps to repro, expected vs actual, suspected scope.
Batch the set to Opus (full file outputs; explain changes). Re-run this checklist to verify.

Gate to proceed from the phase: no open P0; P1 in-scope are fixed or explicitly deferred with rationale.






Plateau-exit checklist (deep pass; end-to-end, multi-project, long session)

A) End-to-end routing (non-stream and stream)
Use the test prompts table from the architecture doc to confirm classification and routing (casual → OpenAI; simple code → Anthropic; architecture → Anthropic; image/ocr → Gemini). Confirm console shows classification lines and chosen provider/model; UI badges match.

B) Multi-project memory integrity
Create 3 projects with distinct histories, notes, and files. Swap among them repeatedly; restart backend and desktop; confirm perfect isolation and full persistence.
Export/reload (if supported); verify indexes rebuild without drift.

C) Security & privacy
Master key present (exact length, correct label); encryption ready; secrets scrubbed in logs; DB at-rest encryption verified; no credentials in .env prints or UI; failure paths (bad key, missing key) show clear errors without leaking secrets.

D) UI & UX correctness
Scrolling behaviours in chat and history panels; markdown (tables, fenced code, inline code); long responses do not freeze UI; drag-drop large file shows progress + error states; model badges always present.

E) Multimodal (Gemini tiers)
Flash tier: screenshots, single-page PDFs, quick OCR → fast, correct, cheap path; proper labels.
Gemini 3.0/3 Pro:
Critique a large Opus output (architecture + multi-file patch): expects structured issues, risks, missing edge cases.
Analyse a long video: timestamps, cuts, narrative suggestions; output usable in editing workflow.

F) Web search & grounding
Query returns grounded snippets; network failures handled (timeouts, 429) with retries/backoff; no UI lock-ups.

G) Embeddings/RAG
Auto-index new notes/messages/files; semantically retrieve across projects (only where permitted); large file does not block chat; partial indexing failure emits recoverable errors.

H) Job engine / artefacts (if Phase-4 enabled)
JobEnvelope/Result schemas align; modalities_in and needs_tools fields correct; budgets enforced; artefacts saved/loaded; provider registry applies rate-limits and retries; usage log bounded.

I) Streaming robustness
Metadata → tokens → done events in order; premature cancel closes cleanly; streaming to each provider works; routing metadata matches DB record.

J) Error taxonomy & observability
Representative errors map to the right category; logs contain actionable context, not secrets; console output shows routing decisions and classifications you expect.

K) Docs & policy sync
Architecture map updated to match reality (routing, streaming path, classification functions, defaults, troubleshooting).
Routing policy JSON matches actual behaviours; test prompts remain valid; troubleshooting steps are current.

L) Go/No-Go criteria to advance plateau
All P0 closed.
In-scope P1 closed or mitigated with explicit tickets.
Core invariants (routing, memory, security) demonstrably solid across non-stream and stream paths.
UI and model badges correct for all tested jobs.
A fresh “Known Bugs” list exists (only P2/icebox acceptable).
Dynamic growth rules (keep the checklists current)

When you add or change a module, register it under “Delta checks” with:
Name, Owner, Dependencies, Happy path, Failure path, Restart-persistence, Log/metrics.
When a module becomes core (used across most flows), promote its tests into the phase checklist.
When a module affects security/routing/memory, add dedicated plateau tests and keep them until two consecutive plateaus pass green.
Keep a small, fixed set of routing prompts and console strings as golden tests so regressions are obvious.