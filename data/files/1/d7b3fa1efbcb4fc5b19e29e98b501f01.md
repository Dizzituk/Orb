# Orb Architecture Map

**Version:** 0.7.1 (Architecture Map v4)  
**Last Updated:** 30 November 2025  
**Purpose:** Canonical architecture reference for the Orb multi-LLM AI assistant system

---

## Table of Contents

1. [System Overview](#system-overview)  
2. [Component Architecture](#component-architecture)  
3. [Backend (`Orb`)](#backend-orb)  
4. [Desktop Client (`orb-desktop`)](#desktop-client-orb-desktop)  
5. [Data Layer](#data-layer)  
6. [Multi-LLM Orchestration](#multi-llm-orchestration)  
7. [File Ingestion Pipeline](#file-ingestion-pipeline)  
8. [Image Analysis Pipeline](#image-analysis-pipeline)  
9. [Future Capabilities](#future-capabilities)  
10. [Changelog](#changelog)

---

## System Overview

Orb is a personal AI assistant built as a multi-component system with specialized LLM roles:

- **GPT (OpenAI)** — Fast/lightweight reasoning, conversational interface, linguistics  
- **Claude (Anthropic)** — Flagship engineer, complex code, architecture design  
- **Gemini (Google)** — Critic, reviewer, analyst, vision specialist  

### Core Vision

Different AI models specialize in distinct roles while sharing a unified memory layer, enabling:

- Persistent knowledge management across conversations  
- Task coordination and project organization  
- Job-type-based automatic model routing  
- File upload with text extraction and document analysis  
- CV parsing with structured data extraction  
- Image analysis via Gemini Vision  
- RAG-based document retrieval for Q&A  

### Technology Stack

**Backend:**

- FastAPI (Python 3.13)  
- SQLAlchemy ORM  
- SQLite database  
- Pydantic schemas  
- `python-multipart` for `multipart/form-data` file uploads  
- `python-docx` for DOCX text extraction  
- `PyMuPDF` (fitz) for PDF text extraction  
- `google-generativeai` for Gemini Vision  

**Desktop Client:**

- Electron (v33.0.0)  
- React 18 with TypeScript 5  
- Vite 5 (build tool and dev server)  
- Custom React hooks for state management  

**Platform:** Windows 11

---

## Component Architecture

```text
D:/
├── Orb/                        # Backend (FastAPI server)
│   ├── main.py                 # Application entrypoint, chat endpoints
│   ├── .env                    # API keys (OPENAI, ANTHROPIC, GOOGLE, GEMINI_VISION_MODEL)
│   ├── app/
│   │   ├── db.py               # Database configuration
│   │   ├── memory/             # Memory subsystem (projects/notes/tasks/files/messages/documents)
│   │   └── llm/                # LLM routing module + vision
│   ├── data/                   # SQLite DB + file storage
│   │   ├── orb_memory.db       # SQLite database
│   │   └── files/              # Per-project file storage
│   │       └── {project_id}/   # Uploaded project files (CVs, docs, images, etc.)
│   └── static/                 # Web-based test UI
│
├── orb-desktop/                # Electron + React desktop client
│   ├── main.js                 # Electron main process
│   ├── index.html              # React mount point + CSP config
│   ├── package.json            # Dependencies + scripts
│   ├── vite.config.ts          # Vite configuration
│   ├── tsconfig.json           # TypeScript configuration
│   └── src/
│       ├── main.tsx            # React entry point
│       ├── App.tsx             # Root component, layout orchestration
│       ├── components/         # React components
│       ├── hooks/              # Custom React hooks
│       ├── services/           # API client layer
│       ├── styles/             # CSS styles
│       └── types/              # TypeScript type definitions
│
└── orb-electron-data/          # Electron userData directory
    └── [cache, logs, settings] # NOT PART OF CODEBASE
```

---

## Backend (`Orb`)

**Location:** `D:/Orb/`  
**Framework:** FastAPI  
**Entry Point:** `main.py`  
**Version:** 0.7.1

### Directory Structure

```text
Orb/
├── main.py                 # FastAPI app, endpoints, context building, RAG
├── chat_memory.py          # Legacy in-memory chat store (not currently used)
├── .env                    # API keys and configuration
├── start_orb_backend.bat   # Windows startup script
│
├── app/
│   ├── __init__.py
│   ├── db.py               # Database engine, session factory, Base
│   │
│   ├── memory/             # Memory subsystem
│   │   ├── __init__.py
│   │   ├── models.py       # SQLAlchemy ORM models (inc. DocumentContent)
│   │   ├── schemas.py      # Pydantic request/response schemas
│   │   ├── service.py      # Business logic (CRUD operations)
│   │   └── router.py       # FastAPI route handlers
│   │
│   └── llm/                # LLM routing module
│       ├── __init__.py     # Exports: call_llm, LLMTask, LLMResult, JobType, analyze_image, etc.
│       ├── schemas.py      # JobType enum, LLMTask/LLMResult models, RoutingConfig
│       ├── clients.py      # Provider API wrappers (internal only)
│       ├── router.py       # Main router with call_llm() function
│       ├── gemini_vision.py # Gemini Vision client for image analysis
│       └── file_analyzer.py # Text extraction and document analysis
│
├── data/
│   ├── orb_memory.db       # SQLite database file
│   └── files/              # On-disk storage for uploaded project files
│       └── {project_id}/   # Project-specific file directories
│
├── static/                 # Web-based test interface
│   ├── index.html
│   └── renderer.js
│
└── .venv/                  # Python virtual environment
```

### Environment Configuration (`.env`)

```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...
GEMINI_VISION_MODEL=gemini-2.0-flash
```

### Core Modules

#### `main.py`

- FastAPI app initialization with CORS middleware  
- Database initialization on startup  
- Environment variable validation on startup  
- Context building functions:
  - `build_context_block(db, project_id)` — fetches recent notes + open tasks  
  - `build_document_context(db, project_id, user_message)` — RAG retrieval for uploaded documents  
- Endpoints:
  - `GET /` — serves static UI  
  - `GET /ping` — health check  
  - `POST /chat` — main chat endpoint with RAG (routes via job_type)  
  - `POST /chat_with_attachments` — file upload with extraction/analysis  
  - `POST /llm` — direct LLM call (no project context)  
  - `GET /providers` — which provider keys are configured  
  - `GET /job-types` — list configured job types  
  - Includes `/memory/*` router  

#### CORS Configuration

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",   # Vite dev server
        "http://localhost:8000",   # Backend itself
        "http://127.0.0.1:5173",
        "http://127.0.0.1:8000",
        "file://",                 # Electron file:// protocol
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

### LLM Routing Module (`app/llm/`)

Routing layer for all model calls plus file analysis utilities.

#### `__init__.py` — Exports

```python
from .router import call_llm, quick_chat, request_code, review_work
from .schemas import LLMTask, LLMResult, JobType, Provider, RoutingConfig
from .gemini_vision import analyze_image, is_image_mime_type
from .file_analyzer import (
    extract_text_content,
    detect_document_type,
    parse_cv_with_llm,
    generate_document_summary,
)
```

#### `schemas.py` — Types and Routing Config

- `JobType` enum:
  - GPT-only: `casual_chat`, `note_cleanup`, `copywriting`, `prompt_shaping`, `summary`, `explanation`
  - Medium dev: `simple_code_change`, `small_bugfix`
  - Claude (engineering): `complex_code_change`, `codegen_full_file`, `architecture_design`, `code_review`, `spec_review`, `refactor`, `implementation_plan`
  - High-stakes: `high_stakes_infra`, `security_sensitive_change`, `privacy_sensitive_change`, `public_app_packaging`
  - Gemini: `image_analysis`, `screenshot_analysis`, `video_analysis`
- `Provider` enum: `OPENAI`, `ANTHROPIC`, `GOOGLE`
- `LLMTask`, `LLMResult`, `RoutingConfig`

#### `clients.py`

Provider wrappers (internal):

- `call_openai(...)`
- `call_anthropic(...)`
- `call_google(...)`
- `check_provider_availability()`

Models:

- OpenAI: `gpt-4.1-mini`
- Anthropic: `claude-sonnet-4`
- Google: `gemini-2.0-flash`

#### `router.py`

- `call_llm(task: LLMTask) -> LLMResult` — single entry point  
- Convenience helpers:
  - `quick_chat(...)` → GPT  
  - `request_code(...)` → Claude  
  - `review_work(...)` → Gemini  
- Enforces Claude rules:
  - Ask for full file before edits  
  - Return complete files, no diffs/snippets  

#### `gemini_vision.py` — Image Analysis

```python
def analyze_image(image_bytes: bytes, mime_type: str, user_prompt: Optional[str] = None) -> dict:
    """
    Analyze an image using Gemini Vision.
    
    Returns:
        dict with keys: summary, tags, type, and optionally error
    """
```

Features:
- Lazy-loads Gemini model on first use
- Reads `GOOGLE_API_KEY` and `GEMINI_VISION_MODEL` from environment
- Handles multiple `.env` file locations as fallback
- Returns structured JSON with summary, tags, and image type
- Graceful error handling — returns error dict instead of raising

#### `file_analyzer.py` — Document Processing

```python
def extract_text_content(file_path: str) -> Optional[str]:
    """Extract text from DOCX, PDF, TXT, MD, and other text files."""

def detect_document_type(filename: str, content: str) -> str:
    """Detect document type: cv, code, config, data, document."""

def parse_cv_with_llm(raw_text: str, filename: str, llm_call_fn) -> dict:
    """Parse CV into structured data: name, summary, roles, skills, education."""

def generate_document_summary(raw_text: str, filename: str, doc_type: str, llm_call_fn) -> str:
    """Generate a 2-3 sentence summary of a document."""
```

Supported file types:
- `.docx` — via `python-docx` (paragraphs + tables)
- `.pdf` — via `PyMuPDF` (fitz)
- `.txt`, `.md`, `.csv`, `.json`, `.xml`, `.yaml` — plain text
- `.py`, `.js`, `.ts`, `.html`, `.css` — code files

---

## Memory Subsystem (`app/memory/`)

Project-based knowledge management with document content storage.

### `models.py` — ORM Models

```python
class Project:
    id, name, description, created_at, updated_at
    # Relationships: notes, tasks, files, messages, document_contents

class Note:
    id, project_id, title, content, tags, source, created_at, updated_at

class Task:
    id, project_id, title, description, status, priority, created_at, updated_at

class File:
    id, project_id, path, original_name, file_type, description, created_at
    # Relationship: document_content (one-to-one)

class Message:
    id, project_id, role, content, created_at

class DocumentContent:  # NEW in v0.7.0
    id, project_id, file_id, filename, doc_type
    raw_text        # Full extracted text
    summary         # LLM-generated summary
    structured_data # JSON string (e.g., parsed CV data)
    created_at
```

### `schemas.py` — Pydantic

Existing schemas plus:

```python
class DocumentContentCreate(BaseModel):
    project_id: int
    file_id: int
    filename: str
    doc_type: str
    raw_text: Optional[str] = None
    summary: Optional[str] = None
    structured_data: Optional[str] = None

class DocumentContentOut(BaseModel):
    id: int
    project_id: int
    file_id: int
    filename: str
    doc_type: str
    raw_text: Optional[str]
    summary: Optional[str]
    structured_data: Optional[str]
    created_at: datetime
```

### `service.py` — Business Logic

Existing functions plus document content operations:

```python
# Document Content CRUD
def create_document_content(db, data: DocumentContentCreate) -> DocumentContent
def get_document_content_by_file_id(db, file_id: int) -> Optional[DocumentContent]
def get_document_content_by_filename(db, project_id: int, filename: str) -> Optional[DocumentContent]
def list_document_contents(db, project_id: int) -> List[DocumentContent]
def search_document_contents(db, project_id: int, query: str) -> List[DocumentContent]
def get_latest_document_content(db, project_id: int) -> Optional[DocumentContent]
```

### `router.py` — Memory API

All prefixed with `/memory`. (Unchanged from v0.6.0)

---

## Desktop Client (`orb-desktop`)

React + TypeScript Electron application.

**Location:** `D:/orb-desktop/`  
**Framework:** React 18, TypeScript 5, Vite 5, Electron 33

### Directory Structure

```text
orb-desktop/
├── main.js                 # Electron main process
├── index.html              # React mount point + CSP
├── package.json            # Dependencies and scripts
├── vite.config.ts          # Vite configuration
├── tsconfig.json           # TypeScript configuration
│
└── src/
    ├── main.tsx            # React entry point
    ├── App.tsx             # Root component, two-column layout
    ├── vite-env.d.ts       # Vite type declarations
    │
    ├── types/
    │   └── index.ts        # TypeScript interfaces
    │
    ├── services/
    │   └── api.ts          # HTTP client for backend
    │
    ├── hooks/
    │   ├── index.ts        # Hook exports
    │   ├── useChat.ts      # Message state, send logic
    │   ├── useAttachments.ts # File selection, previews
    │   └── useCodeFiles.ts # Code block parsing
    │
    ├── components/
    │   ├── index.ts        # Component exports
    │   ├── Header.tsx      # Status display, reset button
    │   ├── ChatWindow.tsx  # Message history, auto-scroll
    │   ├── MessageBubble.tsx # Individual messages
    │   ├── AttachmentBar.tsx # Pending file chips
    │   ├── InputSection.tsx  # Textarea, attach, send
    │   └── CodeFilesPanel.tsx # Generated code viewer
    │
    └── styles/
        └── index.css       # Global styles, dark theme
```

### Configuration Files

#### `package.json`

```json
{
  "name": "orb-desktop",
  "version": "0.7.1",
  "main": "main.js",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "start": "npm run build && electron .",
    "electron:dev": "concurrently \"vite\" \"wait-on http://localhost:5173 && electron .\""
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@vitejs/plugin-react": "^4.2.0",
    "concurrently": "^8.2.0",
    "electron": "^33.0.0",
    "typescript": "^5.3.0",
    "vite": "^5.0.0",
    "wait-on": "^7.2.0"
  }
}
```

#### `vite.config.ts`

```typescript
export default defineConfig({
  plugins: [react()],
  base: './',
  server: { port: 5173 },
  build: { outDir: 'dist' }
})
```

#### `index.html` — CSP Configuration

```html
<meta http-equiv="Content-Security-Policy" content="
  default-src 'self';
  img-src 'self' blob: data:;
  script-src 'self' 'unsafe-inline';
  style-src 'self' 'unsafe-inline';
  connect-src 'self' http://localhost:8000;
" />
```

### TypeScript Types (`src/types/index.ts`)

```typescript
interface Message {
  id: string
  role: 'user' | 'assistant' | 'system'
  content: string
  attachments?: AttachmentMeta[]
  attachmentsSummary?: AttachmentSummary[]
}

interface AttachmentMeta {
  name: string
  type: string
  previewUrl?: string
}

interface AttachmentSummary {
  client_filename: string
  stored_id: string
  type: string
  summary: string
  tags: string[]
}

interface PendingAttachment {
  file: File
  previewUrl?: string
}

interface ChatResponse {
  project_id: number
  provider: string
  reply: string
  was_reviewed?: boolean
  critic_review?: string
  attachments_summary?: AttachmentSummary[]
}

interface GeneratedFile {
  filename: string
  language: string
  content: string
}
```

### API Service (`src/services/api.ts`)

```typescript
const API_BASE = 'http://localhost:8000'

export async function chat(projectId: number, message: string, jobType?: string): Promise<ChatResponse>
export async function chatWithAttachments(projectId: number, message: string, files: File[], jobType?: string): Promise<ChatResponse>
export async function uploadFile(projectId: number, file: File): Promise<FileUploadResponse>
export async function clearMessages(projectId: number): Promise<void>
export async function ping(): Promise<boolean>
```

### Custom Hooks

#### `useChat.ts`

- Manages `messages` state array
- `sendMessage(text, attachments)` — routes to `/chat` or `/chat_with_attachments`
- `addSystemMessage(text)` — for UI notifications
- `resetChat()` — clears messages, calls backend delete
- `status` — 'ready' | 'thinking' | 'error'

#### `useAttachments.ts`

- Manages `pendingAttachments` array
- `addFiles(FileList)` — creates preview URLs for images
- `removeAttachment(index)` — removes and revokes preview URL
- `clearAll()` — cleanup all previews

#### `useCodeFiles.ts`

- Parses fenced code blocks from assistant messages
- Extracts filenames from comments: `# file:`, `// file:`, `<!-- file: -->`
- Provides `copyToClipboard(file)` and `downloadFile(file)`

### Components

#### `App.tsx` — Layout

```tsx
<div className="app">
  <Header status={status} onReset={resetChat} />
  <main className="app-main">
    <ChatWindow messages={messages} status={status} />
    <CodeFilesPanel files={codeFiles} />
  </main>
  <AttachmentBar attachments={pending} onRemove={remove} />
  <InputSection onSend={send} onAttach={attach} disabled={status === 'thinking'} />
</div>
```

#### Two-Column Layout

- **Left (ChatWindow):** Message history with auto-scroll, attachment summaries
- **Right (CodeFilesPanel):** Generated code files with syntax display, copy/download

---

## Data Layer

### Database

- SQLite at `data/orb_memory.db`
- Tables: `projects`, `notes`, `tasks`, `files`, `messages`, `document_contents`

### Files on Disk

- Folder structure: `data/files/{project_id}/`
- DB `File.path` stores relative `files/{project_id}/{uuid}.{ext}`
- Images, documents, and all uploaded files stored here

### Document Content Storage

When files are uploaded via `/chat_with_attachments`:

1. File saved to disk
2. Text extracted (DOCX/PDF/TXT)
3. Document type detected
4. For CVs: structured data parsed (name, roles, skills, education)
5. Summary generated
6. `DocumentContent` record created with raw_text, summary, structured_data

---

## Multi-LLM Orchestration

### Job-Type Based Routing

- `/chat` uses `JobType` to decide provider(s)
- GPT for low-stakes text, Claude for engineering, Gemini for reviews/vision
- High-stakes flows may route to Claude and then have Gemini critique

### RAG Document Retrieval

The `/chat` endpoint includes RAG-based document context:

```python
def build_document_context(db, project_id, user_message):
    # 1. Check for CV-related keywords
    # 2. Check for filename mentions
    # 3. Keyword match against document content
    # 4. Fall back to most recent document
    # 5. Build context with structured_data + summary + raw_text excerpt
```

System prompt instructs LLM to use UPLOADED DOCUMENTS section for answers.

### Response Shape

```json
{
  "project_id": 1,
  "provider": "anthropic",
  "reply": "Based on your CV, you worked as a Bar Manager at Cosy Club from March to October 2017...",
  "was_reviewed": false,
  "critic_review": null,
  "attachments_summary": [
    {
      "client_filename": "Tazzid Ingram cv.docx",
      "stored_id": "file_1",
      "type": "cv",
      "summary": "CV for Tazzid Ingram with 5 work experiences, skills include: ...",
      "tags": ["cv", "resume", "docx"]
    }
  ]
}
```

---

## File Ingestion Pipeline

### Flow: Document Upload → Extraction → Storage → Q&A

```text
User uploads file
       │
       ▼
POST /chat_with_attachments
       │
       ├── Save to data/files/{project_id}/{uuid}.{ext}
       │
       ├── Detect MIME type
       │         │
       │         ├── image/* → analyze_image() via Gemini Vision
       │         │
       │         └── document → extract_text_content()
       │                              │
       │                              ├── .docx → python-docx
       │                              ├── .pdf  → PyMuPDF
       │                              └── .txt/.md → plain read
       │
       ├── detect_document_type() → cv | code | config | document
       │
       ├── If CV: parse_cv_with_llm() → structured JSON
       │   {name, summary, roles[], skills[], education[]}
       │
       ├── generate_document_summary()
       │
       ├── Create File record in DB
       │
       ├── Create DocumentContent record
       │   (raw_text, summary, structured_data)
       │
       └── Return ChatResponse with attachments_summary
```

### Q&A Flow

```text
User asks: "When was I a barman?"
       │
       ▼
POST /chat
       │
       ├── build_document_context()
       │         │
       │         ├── Detect CV query keywords
       │         ├── Find matching DocumentContent records
       │         └── Build context with structured_data + raw_text
       │
       ├── Inject into system prompt
       │
       └── LLM answers from document context
           "Your CV shows you were a Bar Manager at Cosy Club, Exeter 
            from March 2017 to October 2017."
```

---

## Image Analysis Pipeline

### Flow: Image Upload → Gemini Vision → Storage

```text
User uploads image
       │
       ▼
POST /chat_with_attachments
       │
       ├── Save to data/files/{project_id}/{uuid}.png
       │
       ├── Detect image/* MIME type
       │
       ├── analyze_image(file_bytes, mime_type, user_prompt)
       │         │
       │         ├── Load GOOGLE_API_KEY from .env
       │         ├── Initialize Gemini model (lazy)
       │         ├── Send image + prompt to Gemini Vision
       │         └── Parse JSON response: {summary, tags, type}
       │
       ├── Create File record
       │
       ├── Create DocumentContent record
       │   (raw_text = "[Image: filename] summary")
       │
       └── Return ChatResponse with image summary
```

### Gemini Vision Configuration

```env
GOOGLE_API_KEY=AIza...
GEMINI_VISION_MODEL=gemini-2.0-flash  # or gemini-3-pro-preview
```

---

## Future Capabilities

Planned next steps:

1. **Semantic Search Over Notes & Files**
   - Embedding-based retrieval for long-term memory
   - Vector store integration (ChromaDB or similar)

2. **Streaming Responses**
   - Token streaming in Electron UI
   - Server-sent events from FastAPI

3. **More Tools / Function Calling**
   - LLM-triggered tools for internal Orb operations
   - Calendar integration, web search, etc.

4. **Project Selector UI**
   - Currently hardcoded to Project ID 1
   - Add project creation/selection in desktop client

5. **Web Search Grounding**
   - Real-time web search for current information
   - Gemini grounding API integration

6. **Voice Input/Output**
   - Speech-to-text for input
   - Text-to-speech for responses

---

## Changelog

### v0.7.1 — Image Analysis Pipeline (30 Nov 2025)

- Fixed `gemini_vision.py` to properly load `.env` with `load_dotenv()`
- Added fallback `.env` path detection
- Improved error handling — returns error dict instead of crashing
- Added startup environment variable validation
- Added debug logging throughout image analysis flow

### v0.7.0 — React Migration + File Ingestion (29-30 Nov 2025)

**Desktop Client (orb-desktop):**

- Complete rewrite from vanilla JavaScript to React 18 + TypeScript 5
- Vite 5 as build tool and dev server
- Custom hooks architecture: `useChat`, `useAttachments`, `useCodeFiles`
- Typed API service layer
- Two-column layout: ChatWindow + CodeFilesPanel
- Component-based UI: Header, MessageBubble, AttachmentBar, InputSection
- CSP configuration for blob: image previews
- Concurrent dev workflow: Vite + Electron

**Backend (Orb):**

- New `POST /chat_with_attachments` endpoint for file uploads
- Text extraction pipeline: DOCX (python-docx), PDF (PyMuPDF), TXT
- Document type detection: cv, code, config, document
- CV parsing with structured data extraction (roles, skills, education)
- `DocumentContent` model for storing extracted text and summaries
- RAG-based document retrieval in `/chat` endpoint
- `build_document_context()` for intelligent document selection
- Gemini Vision integration for image analysis
- CORS middleware for localhost:5173 (Vite dev server)

**Dependencies Added:**

- `python-docx` — DOCX text extraction
- `PyMuPDF` — PDF text extraction
- `google-generativeai` — Gemini Vision API

### v0.6.0 — File Upload Plumbing (28 Nov 2025)

- Added real file upload into Orb backend
- `POST /memory/projects/{project_id}/files/upload` with `multipart/form-data`
- `File` ORM row created via `service.create_file_for_project`
- Electron desktop: attachment button and drag-drop wired to backend

---

## Quick Start

### Backend

```powershell
cd D:\Orb
.venv\Scripts\activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Desktop Client

```powershell
cd D:\orb-desktop
npm run electron:dev
```

### Verify `.env`

```powershell
Get-Content D:\Orb\.env
# Should show:
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GOOGLE_API_KEY=AIza...
# GEMINI_VISION_MODEL=gemini-2.0-flash
```

---

## Troubleshooting

### CORS Errors

If you see "No 'Access-Control-Allow-Origin' header":
- Verify CORS middleware in `main.py` includes `http://localhost:5173`
- Restart backend after changes

### CSP Errors (blob: images)

If image previews don't load:
- Check `index.html` CSP includes `img-src 'self' blob: data:`

### GOOGLE_API_KEY Not Found

If image analysis fails with "GOOGLE_API_KEY is not set":
- Verify `.env` file exists at `D:\Orb\.env`
- Check format: `GOOGLE_API_KEY=AIza...` (no quotes, no spaces)
- Restart backend to reload environment

### Document Q&A Not Working

If Orb can't answer questions about uploaded files:
- Delete old database: `del D:\Orb\data\orb_memory.db`
- Restart backend (recreates tables with DocumentContent)
- Re-upload files
